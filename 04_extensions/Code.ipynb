{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiments for:\n",
    "\n",
    "* Loss functions\n",
    "* Learning rate decay\n",
    "* Weight initialization\n",
    "* Optimizers\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `lincoln` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import SoftmaxCrossEntropy, MeanSquaredError\n",
    "from lincoln.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from lincoln.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from lincoln.network import NeuralNetwork\n",
    "from lincoln.train import Trainer\n",
    "from lincoln.utils import mnist\n",
    "from lincoln.utils.np_utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist.init() Use the function once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(y_train)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "some_digit = X_train[45]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.subplot(1, 1, 1)\n",
    "image = some_digit_image\n",
    "plt.imshow(image.astype(np.uint8))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data to mean 0, variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.318421449829934,\n",
       " 221.68157855017006,\n",
       " -33.318421449829934,\n",
       " 221.68157855017006)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train) # https://wiki.loginom.ru/articles/data-standartization.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.424073894391566, 2.821543345689335, -0.424073894391566, 2.821543345689335)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.611\n",
      "Validation loss after 20 epochs is 0.426\n",
      "Validation loss after 30 epochs is 0.388\n",
      "Validation loss after 40 epochs is 0.374\n",
      "Validation loss after 50 epochs is 0.365\n",
      "\n",
      "The model validation accuracy is: 72.77%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: even if we normalize the outputs of a classification model with mean squared error loss, it still doesn't help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.952\n",
      "\n",
      "Loss increased after epoch 20, final loss was 0.952, \n",
      "using the model from epoch 10\n",
      "The model validation accuracy is: 41.73%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that we should be using softmax cross entropy loss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 1.285\n",
      "Validation loss after 2 epochs is 0.970\n",
      "Validation loss after 3 epochs is 0.836\n",
      "Validation loss after 4 epochs is 0.763\n",
      "Validation loss after 5 epochs is 0.712\n",
      "Validation loss after 6 epochs is 0.679\n",
      "Validation loss after 7 epochs is 0.651\n",
      "Validation loss after 8 epochs is 0.631\n",
      "Validation loss after 9 epochs is 0.617\n",
      "Validation loss after 10 epochs is 0.599\n",
      "Validation loss after 11 epochs is 0.588\n",
      "Validation loss after 12 epochs is 0.576\n",
      "Validation loss after 13 epochs is 0.568\n",
      "Validation loss after 14 epochs is 0.557\n",
      "Validation loss after 15 epochs is 0.550\n",
      "Validation loss after 16 epochs is 0.544\n",
      "Validation loss after 17 epochs is 0.537\n",
      "Validation loss after 18 epochs is 0.533\n",
      "Validation loss after 19 epochs is 0.529\n",
      "Validation loss after 20 epochs is 0.523\n",
      "Validation loss after 21 epochs is 0.517\n",
      "Validation loss after 22 epochs is 0.512\n",
      "Validation loss after 23 epochs is 0.507\n",
      "\n",
      "Loss increased after epoch 24, final loss was 0.507, \n",
      "using the model from epoch 23\n",
      "\n",
      "The model validation accuracy is: 91.04%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 130,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 6.610\n",
      "\n",
      "Loss increased after epoch 20, final loss was 6.610, \n",
      "using the model from epoch 10\n",
      "\n",
      "The model validation accuracy is: 69.11%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=ReLU()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.629\n",
      "Validation loss after 20 epochs is 0.570\n",
      "Validation loss after 30 epochs is 0.553\n",
      "Validation loss after 40 epochs is 0.549\n",
      "\n",
      "Loss increased after epoch 50, final loss was 0.549, \n",
      "using the model from epoch 40\n",
      "\n",
      "The model validation accuracy is: 90.92%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 0.615\n",
      "Validation loss after 2 epochs is 0.489\n",
      "Validation loss after 3 epochs is 0.447\n",
      "\n",
      "Loss increased after epoch 4, final loss was 0.447, \n",
      "using the model from epoch 3\n",
      "The model validation accuracy is: 92.35%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, optim)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 1,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.388\n",
      "Validation loss after 20 epochs is 0.351\n",
      "Validation loss after 30 epochs is 0.322\n",
      "Validation loss after 40 epochs is 0.313\n",
      "\n",
      "Loss increased after epoch 50, final loss was 0.313, \n",
      "using the model from epoch 40\n",
      "The model validation accuracy is: 95.63%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGD(0.1)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, optim)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.405\n",
      "Validation loss after 20 epochs is 0.309\n",
      "Validation loss after 30 epochs is 0.276\n",
      "\n",
      "Loss increased after epoch 40, final loss was 0.276, \n",
      "using the model from epoch 30\n",
      "The model validation accuracy is: 95.99%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(lr=0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.518\n",
      "Validation loss after 20 epochs is 0.330\n",
      "Validation loss after 30 epochs is 0.294\n",
      "\n",
      "Loss increased after epoch 40, final loss was 0.294, \n",
      "using the model from epoch 30\n",
      "The model validation accuracy is: 95.91%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(lr=0.2, \n",
    "                        momentum=0.9, \n",
    "                        final_lr = 0.05, \n",
    "                        decay_type='exponential')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.350\n",
      "Validation loss after 20 epochs is 0.249\n",
      "Validation loss after 30 epochs is 0.241\n",
      "\n",
      "Loss increased after epoch 40, final loss was 0.241, \n",
      "using the model from epoch 30\n",
      "The model validation accuracy is: 96.89%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(lr=0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.363\n",
      "Validation loss after 20 epochs is 0.266\n",
      "Validation loss after 30 epochs is 0.243\n",
      "\n",
      "Loss increased after epoch 40, final loss was 0.243, \n",
      "using the model from epoch 30\n",
      "The model validation accuracy is: 96.44%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr=0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.283\n",
      "Validation loss after 20 epochs is 0.243\n",
      "Validation loss after 30 epochs is 0.207\n",
      "Validation loss after 40 epochs is 0.183\n",
      "\n",
      "Loss increased after epoch 50, final loss was 0.183, \n",
      "using the model from epoch 40\n",
      "The model validation accuracy is: 97.04%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr=0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning, with and without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.330\n",
      "Validation loss after 20 epochs is 0.284\n",
      "Validation loss after 30 epochs is 0.256\n",
      "Validation loss after 40 epochs is 0.230\n",
      "Validation loss after 50 epochs is 0.213\n",
      "Validation loss after 60 epochs is 0.212\n",
      "Validation loss after 70 epochs is 0.193\n",
      "Validation loss after 80 epochs is 0.181\n",
      "\n",
      "Loss increased after epoch 90, final loss was 0.181, \n",
      "using the model from epoch 80\n",
      "The model validation accuracy is: 97.23%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr=0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.423\n",
      "Validation loss after 20 epochs is 0.384\n",
      "Validation loss after 30 epochs is 0.306\n",
      "Validation loss after 40 epochs is 0.292\n",
      "Validation loss after 50 epochs is 0.279\n",
      "Validation loss after 60 epochs is 0.252\n",
      "Validation loss after 70 epochs is 0.252\n",
      "\n",
      "Loss increased after epoch 80, final loss was 0.252, \n",
      "using the model from epoch 70\n",
      "The model validation accuracy is: 96.17%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(lr=0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acc44b3279df879ed67cbea63caa70c1a6161b5ecc0483bd33f32a22c22afd79"
  },
  "kernelspec": {
   "display_name": "dlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
